---
title: 我对Web后台的一些看法
tags: [Web]
category: 技术探索
date: 2016-09-29 00:41:13
---

1\. qps, 曾今分析过公司的Nginx日志，单台应用服务器的日访问量大约等于30000*峰值qps，而我们web服务的单日访问最高达8亿，如此算来，我们web服务的峰值qps也有25000以上，当然，实际到达后端web应用的访问应该不到其1/4，这些访问又会分发到不同的服务器上。具体到每台服务器，假设每个请求耗费10msCPU时间，单台服务器是16核，完美情况下单台服务器能处理的最高qps也就是100*16=1600。
2\. 服务器抗压分析，首先当然是数据库，处理一个请求时，业务逻辑上的处理，可以通过增加服务器来解决，但是通常为了数据的一致性，数据都存在一个数据库中，高并发时，数据库的访问压力会比较大，解决方案通常是优化业务代码，减少数据库访问，对数据库建立适当的索引，数据库主从甚至多主，使用缓存。如果业务逻辑比较复杂，处理一个请求的时间相对较长，可以考虑使用消息队列，专门一组机器处理后台逻辑。如果后台处理时，IO操作比较多，后台web服务器的网络架构最好选择事件驱动模式或混合模式。根据业务，可以分组服务器。静态文件可以使用CDN等。
3\. 页面加载速度，首先是从客户端发出请求，到收到所有数据，这个过程就像在客户端和服务器之间架有一条管道，首先一部分水从客户端流向服务器，之后服务器返回响应水流。管道的长度，BGP多线，CDN的存在，就是为了缩短管道的长度。从服务器端收到请求，到服务器开始返回响应，可尽量降低后台处理请求的时间（后端缓存，异步处理数据等）。服务器响应数据的大小，假设用户使用移动3G网络，网速为100KB/s，如果一个页面的数据（包括js,css,图片）是400KB（电脑版baidu首页的级别），只是下载数据就至少需要4s（排除客户端缓存）。前端优化可见[这里](https://segmentfault.com/a/1190000000735395)。